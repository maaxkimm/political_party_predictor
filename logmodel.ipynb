{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d333d3-c88e-4cb8-bb92-c55d502db118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geopy import *\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import pearsonr\n",
    "import re\n",
    "\n",
    "cases = pd.read_csv('data/time_series_covid19_confirmed_US.csv') # https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\n",
    "vaccinations = pd.read_csv('data/people_vaccinated_us_timeline.csv') # https://raw.githubusercontent.com/govex/COVID-19/master/data_tables/vaccine_data/us_data/time_series/people_vaccinated_us_timeline.csv\n",
    "counties = pd.read_csv('data/co-est2020.csv', encoding='latin-1') # https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv\n",
    "mask_use = pd.read_csv('data/mask-use-by-county.csv') # https://github.com/nytimes/covid-19-data/blob/master/mask-use/mask-use-by-county.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014120e-b8e8-4882-9b96-e6bfd4b5b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.transform(lambda x: x.fillna('') if x.dtype == 'object' else x.fillna(0))\n",
    "vaccinations = vaccinations.transform(lambda x: x.fillna('') if x.dtype == 'object' else x.fillna(0))\n",
    "mask_use = mask_use.transform(lambda x: x.fillna('') if x.dtype == 'object' else x.fillna(0))\n",
    "counties = counties.transform(lambda x: x.fillna('') if x.dtype == 'object' else x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e5a44-2f74-4f5e-9d97-553b78348991",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties['FIPS'] = counties['STATE']*1000 + counties['COUNTY']\n",
    "counties['FIPS'] = counties['FIPS'].apply(lambda x: str(int(x)).zfill(5))\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d6757-d03d-40ac-b0b2-eeb601ca9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases['FIPS_1'] = cases['FIPS'].apply(lambda x: str(int(x)).zfill(5))\n",
    "mask_use['FIPS_2'] = mask_use['COUNTYFP'].apply(lambda x: str(x).zfill(5))\n",
    "county_data = counties.merge(cases,right_on = 'FIPS_1', left_on = 'FIPS').merge(mask_use,left_on = 'FIPS_1', right_on = 'FIPS_2').drop(columns = ['FIPS_x','FIPS_2','FIPS_y']).rename(columns = {'FIPS_1':'FIPS'})\n",
    "mask_use = mask_use.drop(columns = ['FIPS_2'])\n",
    "cases = cases.drop(columns = ['FIPS_1'])\n",
    "county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16599235-8a33-4079-9d72-f5e94fbc99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5a = county_data.loc[:,'9/12/21':]\n",
    "data_5a.drop(columns=['FIPS', 'COUNTYFP'], inplace=True)\n",
    "sns.heatmap(data_5a.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "plt.title(\"pairwise correlation heatmap\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd92906-2a7e-4c2d-9ba7-d8733dd60d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_q5b = county_data[['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS']]\n",
    "y_q5b = county_data['9/12/21']\n",
    "\n",
    "X_q5b_train, X_q5b_test, y_q5b_train, y_q5b_test = train_test_split(X_q5b, y_q5b, test_size=0.33, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_q5b_train, y_q5b_train)\n",
    "\n",
    "y_pred_test = reg.predict(X_q5b_test)\n",
    "y_pred_train = reg.predict(X_q5b_train)\n",
    "\n",
    "mse_test = mean_squared_error(y_pred_test, y_q5b_test)\n",
    "mse_train = mean_squared_error(y_pred_train, y_q5b_train)\n",
    "\n",
    "test_rmse_cases = np.sqrt(mse_test)\n",
    "train_rmse_cases = np.sqrt(mse_train)\n",
    "\n",
    "train_rmse_cases, test_rmse_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde3f18-2b21-4a45-9ba1-9dab99cdd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q5d = county_data[['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS']]\n",
    "y_q5d = county_data['9/12/21'] / county_data['POPESTIMATE2020']\n",
    "\n",
    "X_q5d_train, X_q5d_test, y_q5d_train, y_q5d_test = train_test_split(X_q5d, y_q5d, test_size=0.33, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_q5b_train, y_q5d_train)\n",
    "\n",
    "y_pred_test = reg.predict(X_q5d_test)\n",
    "y_pred_train = reg.predict(X_q5d_train)\n",
    "\n",
    "mse_test = mean_squared_error(y_pred_test, y_q5d_test)\n",
    "mse_train = mean_squared_error(y_pred_train, y_q5d_train)\n",
    "\n",
    "test_rmse_cpc = np.sqrt(mse_test)\n",
    "train_rmse_cpc = np.sqrt(mse_train)\n",
    "\n",
    "train_rmse_cpc, test_rmse_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c102a2-eacf-4e0f-a846-4a6629719560",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "sns.regplot(x = y_pred_test, y = y_q5d_test, scatter_kws={'s':5})\n",
    "plt.title(\"Predictions versus observations for Q5d\")\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"Observations\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78507ff-d56b-4373-9ed3-eb11e3316a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "q5f_Xy = X_q5d_train.copy()\n",
    "q5f_Xy[\"cases\"] = y_q5d_train\n",
    "\n",
    "for _ in range(1000):\n",
    "    temp = q5f_Xy.sample(frac=1.0, replace = True) #with replacement\n",
    "    tempX = temp.loc[:,:\"ALWAYS\"]\n",
    "    tempY = temp[\"cases\"]\n",
    "    temp_reg = LinearRegression()\n",
    "    temp_reg.fit(tempX, tempY)\n",
    "    models.append(temp_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041267ec-5bc8-4dde-9eb7-8712ddfa78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    y_pred = model.predict(pd.DataFrame(X_q5d_test.iloc[100]).transpose())\n",
    "    y_predictions.append(y_pred)\n",
    "    \n",
    "variance = np.var(y_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_predictions, np.array([y_q5d_test.iloc[100]]*1000))\n",
    "\n",
    "prop_var = variance / mse\n",
    "\n",
    "prop_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048c721-3277-421b-a16d-1dd5efe639c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = pd.read_csv('presidential_elections.csv')[['State','2020']].head(51)\n",
    "vote = vote.replace('D.C.','District of Columbia')\n",
    "\n",
    "daily_diff = vaccinations[['People_Fully_Vaccinated','People_Partially_Vaccinated']].diff()\n",
    "daily_vacc = vaccinations[['Province_State','Date']].join(daily_diff) \n",
    "daily_vacc = daily_vacc.merge(county_data[['STNAME','POPESTIMATE2020']].groupby('STNAME', as_index = False).agg(sum), \n",
    "                 left_on = 'Province_State', right_on= 'STNAME', how = 'left').drop(columns = 'STNAME')\n",
    "daily_vacc['People_Fully_Vaccinated'] = daily_vacc['People_Fully_Vaccinated']/daily_vacc['POPESTIMATE2020']\n",
    "daily_vacc['People_Partially_Vaccinated'] = daily_vacc['People_Partially_Vaccinated']/daily_vacc['POPESTIMATE2020']\n",
    "daily_vacc = daily_vacc.merge(vote, left_on = 'Province_State', right_on = 'State', how = 'right')\n",
    "daily_vacc['2020'] = daily_vacc['2020'].replace('R',1).replace('D',0)\n",
    "daily_vacc = daily_vacc[daily_vacc['Date'] > '2020-12-10'].rename(columns = {'2020':'party'}).drop(columns = 'State')\n",
    "daily_vacc['Date'] = pd.to_datetime(daily_vacc['Date'], format = '%Y-%m-%d')\n",
    "daily_vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1a73b-4d6b-430f-8f2c-1b819443149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df contains daily cases increase\n",
    "df = cases[['Province_State']].join(cases.iloc[:, 11:].diff(axis=1, periods=1)).groupby('Province_State', as_index = False).agg(sum)\n",
    "df= df.transpose()\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0]).reset_index()\n",
    "df = df.melt(id_vars = 'index', value_vars = vote['State'].values)\n",
    "df = df.rename(columns = {'index':'Date', 'value': 'daily_case'})\n",
    "df['Date'] = pd.to_datetime(df['Date'], format = '%m/%d/%y')\n",
    "\n",
    "#merge df (cases data) with vacc data & time (275 days)\n",
    "all_features = daily_vacc.merge(df, on = ['Province_State','Date'])\n",
    "all_features['Date'] = pd.to_datetime(all_features['Date'], format = '%Y-%m-%d')\n",
    "all_features['daily_case'] = all_features['daily_case']/all_features['POPESTIMATE2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617ddc0-6e58-4a18-8ac4-3ff72235ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split for time series, this creates a 90/10 train-validation split \n",
    "X = all_features[['Date','People_Fully_Vaccinated','People_Partially_Vaccinated','daily_case']]\n",
    "X['Date'] = pd.to_datetime(X['Date'], format = '%Y-%m-%d')\n",
    "Y = all_features[['Date','party']]\n",
    "Y['Date'] = pd.to_datetime(Y['Date'], format = '%Y-%m-%d')\n",
    "X_train = X[X['Date']<= '2021-08-15'].set_index('Date')\n",
    "X_test = X[X['Date']> '2021-08-15'].set_index('Date')\n",
    "Y_train = Y[Y['Date']<= '2021-08-15'].set_index('Date')\n",
    "Y_test = Y[Y['Date']> '2021-08-15'].set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98cddc-0901-4bcd-b47f-d79adfcf73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(fit_intercept = True, solver = 'lbfgs')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2fc9f-721b-4451-b908-5755024f70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imported daily deaths data and computed the daily difference of deaths \n",
    "deaths = pd.read_csv('data/deaths.csv')\n",
    "deaths = deaths.sort_values(by = ['state','date']).reset_index()[['date','state','deaths']]\n",
    "deaths['date'] = pd.to_datetime(deaths['date'], format = '%Y-%m-%d')\n",
    "deaths['deaths_diff'] = deaths['deaths'].diff()\n",
    "\n",
    "#dictionary to change abbreviations\n",
    "us_state_to_abbrev = { \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\", \"District of Columbia\": \"DC\", \"American Samoa\": \"AS\", \"Guam\": \"GU\", \"Northern Mariana Islands\": \"MP\", \"Puerto Rico\": \"PR\", \"United States Minor Outlying Islands\": \"UM\", \"U.S. Virgin Islands\": \"VI\", }\n",
    "us_state_to_abbrev = {y:x for x,y in us_state_to_abbrev.items()}\n",
    "\n",
    "#imported daily test data and computed the daily difference of tests\n",
    "tests = pd.read_csv('data/time_series_covid19_US.csv')\n",
    "tests['state'] = tests[['state']].replace({'state':us_state_to_abbrev})\n",
    "tests['Date'] = pd.to_datetime(tests['date'], format = '%m/%d/%Y')\n",
    "tests = tests[['Date','state','tests_combined_total']]\n",
    "tests = tests.sort_values(by = ['state','Date'])\n",
    "tests['tests_diff'] = tests['tests_combined_total'].diff()\n",
    "\n",
    "#merged new features: deaths & tests data to the existing dataframe with original three features\n",
    "all_features_6b = all_features.merge(deaths, left_on = ['Date','Province_State'], right_on = ['date','state'], how = 'left')\n",
    "all_features_6b['Date'] = pd.to_datetime(all_features_6b['Date'], format = '%Y-%m-%d')\n",
    "all_features_6b['deaths_diff_per_capita'] = all_features_6b['deaths_diff']/ all_features_6b['POPESTIMATE2020']\n",
    "# all_features.drop(columns = ['date','state','deaths'])\n",
    "# all_features = all_features[['Province_State','Date','People_Fully_Vaccinated','People_Partially_Vaccinated','POPESTIMATE2020','daily_case','deaths_diff_per_capita','party']]\n",
    "all_features_6b = all_features_6b.merge(tests, left_on = ['Date','Province_State'], right_on = ['Date','state'], how = 'left')\n",
    "all_features_6b['tests_diff_per_capita'] = all_features_6b['tests_diff']/ all_features_6b['POPESTIMATE2020']\n",
    "all_features_6b = all_features_6b[['Province_State','Date','People_Fully_Vaccinated','People_Partially_Vaccinated','POPESTIMATE2020','daily_case','deaths_diff_per_capita','tests_diff_per_capita','party']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf0115-c1e8-4add-a1b0-c7face8be5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "plot_6b = all_features_6b.copy().groupby(['Date','party'], as_index = False).agg(np.mean)\n",
    "plot_6b = plot_6b.merge(all_features_6b[['Date','party','daily_case']].groupby(['Date','party'], as_index = False).agg(np.mean))\n",
    "fig = px.line(plot_6b, x='Date', y='People_Fully_Vaccinated', color = 'party')\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title = {'text': \"Comparison of Parties over Time : Average of Fully Vaccinated People Per Capita\"},\n",
    "    height=700)\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(plot_6b, x='Date', y='People_Partially_Vaccinated', color = 'party')\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title = {'text': \"Comparison of Parties over Time : Average of Partially Vaccinated People Per Capita\"},\n",
    "    height=700)\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(plot_6b, x='Date', y='daily_case', color = 'party')\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title = {'text': \"Comparison of Parties over Time : Average of Daily New Cases Per Capita\"},\n",
    "    height=700)\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(plot_6b, x='Date', y='deaths_diff_per_capita', color = 'party')\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title = {'text': \"Comparison of Parties over Time : Average of Daily New Deaths Per Capita\"},\n",
    "    height=700)\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(plot_6b, x='Date', y='tests_diff_per_capita', color = 'party')\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title = {'text': \"Comparison of Parties over Time : Average of Daily New Tests Per Capita\"},\n",
    "    height=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1227bc9-38ca-49ae-9abe-60ef2aa0ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split for time series, this creates a 70/30 train-validation split \n",
    "X_6b3 = all_features_6b[['Date','People_Fully_Vaccinated','People_Partially_Vaccinated','daily_case','deaths_diff_per_capita','tests_diff_per_capita']]\n",
    "Y_6b3 = all_features_6b[['Date','party']]\n",
    "X_train_6b3 = X_6b3[X_6b3['Date']>= '2021-03-04'].set_index('Date')\n",
    "X_test_6b3 = X_6b3[X_6b3['Date'] <'2021-03-04'].set_index('Date')\n",
    "Y_train_6b3 = Y_6b3[Y_6b3['Date']>= '2021-03-04'].set_index('Date')\n",
    "Y_test_6b3 = Y_6b3[Y_6b3['Date']< '2021-03-04'].set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e56b4-a419-417a-9214-bc024f490449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_6b3 = LogisticRegression(penalty = 'none', fit_intercept = True, solver = 'lbfgs')\n",
    "model_6b3.fit(X_train_6b3, Y_train_6b3)\n",
    "\n",
    "training_accuracy = model_6b3.score(X_train_6b3, Y_train_6b3)\n",
    "print(\"Training Accuracy: \", training_accuracy)\n",
    "testing_accuracy = model_6b3.score(X_test_6b3, Y_test_6b3)\n",
    "print(\"Testing Accuracy: \", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23afae-c144-45ca-b7bb-c28811812b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model_kfold = LogisticRegressionCV(cv=5,random_state = 0)\n",
    "model_kfold.fit(X_6b3.set_index('Date'), Y_6b3.set_index('Date'))\n",
    "acc = model_kfold.score(X_6b3.set_index('Date'), Y_6b3.set_index('Date'))\n",
    "print(\"Model Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e5a1b-5678-4e73-b3dc-11435656b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_kfold.predict(X_6b3.set_index('Date'))\n",
    "tp = np.sum((y_pred_train == 1) & (Y_6b3['party'] == 1))\n",
    "tn = np.sum((y_pred_train == 0) & (Y_6b3['party'] == 0))\n",
    "fp = np.sum((y_pred_train == 1) & (Y_6b3['party'] == 0))\n",
    "fn = np.sum((y_pred_train == 0) & (Y_6b3['party'] == 1))\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b8a76-5964-43cc-a0e0-29c9d77f65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, threshold = roc_curve(Y_6b3.set_index('Date'), model_kfold.predict_proba(X_6b3.set_index('Date'))[:, 1])\n",
    "fig = px.line(x=fpr, y = tpr, hover_name=threshold)\n",
    "fig.update_xaxes(title=\"False Positive Rate\")\n",
    "fig.update_yaxes(title=\"True Positive Rate\")\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    title={\n",
    "    'text': \"ROC Curve Analysis of the Improved Model\",\n",
    "    'y':0.95,\n",
    "    'x':0.5},\n",
    "    height=500)\n",
    "fig.show()\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(Y_train, model.predict_proba(X_train)[:, 1])\n",
    "fig = px.line(x=fpr, y = tpr, hover_name=threshold)\n",
    "fig.update_xaxes(title=\"False Positive Rate\")\n",
    "fig.update_yaxes(title=\"True Positive Rate\")\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    title={\n",
    "    'text': \"ROC Curve Analysis of the Baseline Model\",\n",
    "    'y':0.95,\n",
    "    'x':0.5},\n",
    "    height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6703a0a-7ced-4ebc-af69-d7fc13b662b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime\n",
    "\n",
    "end_date = pd.to_datetime(\"2021-04-07\", format = '%Y-%m-%d')\n",
    "\n",
    "# function tries different k values\n",
    "def search_k(k, model_type, x_set, y_set): # k: 2\n",
    "    for d in range(0,k): # 2 iterations where last iteration predicts the day after tmrw \n",
    "        next_date = end_date + timedelta(days = d) # increment end_date by 1 day\n",
    "        x_train = x_set[x_set['Date'] < next_date].set_index('Date')\n",
    "        y_train = y_set[y_set['Date'] < next_date].set_index('Date')\n",
    "        tmrw = x_set[x_set['Date'] == next_date].set_index('Date')\n",
    "        tmrw_true = y_set[y_set['Date'] == next_date][['party']].values\n",
    "        model_type.fit(x_train, y_train)\n",
    "        y_pred_array = model_type.predict(tmrw)\n",
    "        y_pred = pd.DataFrame(data=y_pred_array, index = [next_date]*51, columns=[\"party\"])\n",
    "        y_train = y_train.append(y_pred)\n",
    "    return y_train, x_set[x_set['Date'] <= next_date].set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d947c0-b096-4d03-ba7f-370772ed790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "result_table_6d = pd.DataFrame(columns=['model_type','k_values','fpr','tpr','auc'])\n",
    "k_values = [2,14]\n",
    "# Train the models and record the results\n",
    "for k in k_values:\n",
    "        y, x = search_k(k,model_kfold, X_6b3, Y_6b3)\n",
    "        y_prob = model_kfold.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        fpr, tpr, threshold = roc_curve(y, model_kfold.predict_proba(x)[:, 1])\n",
    "        result_table_6d = result_table_6d.append({'model_type':'improved_model',\n",
    "                                            'k_values' : k,\n",
    "                                            'fpr' : fpr,\n",
    "                                            'tpr' : tpr,\n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "for k in k_values:\n",
    "        y, x = search_k(k,model, X, Y)\n",
    "        y_prob = model.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        fpr, tpr, threshold = roc_curve(y, model.predict_proba(x)[:, 1])\n",
    "        result_table_6d = result_table_6d.append({'model_type':'baseline_model',\n",
    "                                            'k_values' : k,\n",
    "                                            'fpr' : fpr,\n",
    "                                            'tpr' : tpr,\n",
    "                                            'auc':auc}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef889d-7b90-4332-975f-bc09ae8827cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in result_table_6d.index:\n",
    "    plt.plot(result_table_6d.loc[i]['fpr'], \n",
    "             result_table_6d.loc[i]['tpr'], \n",
    "             label= result_table_6d.loc[i]['model_type'][:8] + \", \" + str(result_table_6d.loc[i]['k_values']) + \" days, \" + \"AUC={:.3f}\".format(result_table_6d.loc[i]['auc']))\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis of Improved vs Baseline Model', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e860c8a-d586-4e2d-9f55-c519e5a33b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "result_table = pd.DataFrame(columns=['model_type','k_values','auc'])\n",
    "\n",
    "# Train the models and record the results\n",
    "for k in range(1,51,5):\n",
    "        y, x = search_k(k,model_kfold, X_6b3, Y_6b3)\n",
    "        y_prob = model_kfold.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        result_table = result_table.append({'model_type':'model_kfold',\n",
    "                                            'k_values' : k,\n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "for k in range(1,51,5):\n",
    "        y, x = search_k(k,model, X, Y)\n",
    "        y_prob = model.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        result_table = result_table.append({'model_type':'model',\n",
    "                                            'k_values' : k,\n",
    "                                            'auc':auc}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c2bf5-4a70-406d-999e-b2665d6ee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = result_table.replace('model_kfold', 'improved_model').replace('model', 'baseline_model')\n",
    "fig = px.line(result_table, x='k_values', y='auc', color='model_type', markers=True)\n",
    "\n",
    "fig.update_xaxes(title=\"Experimented K Values in Days\")\n",
    "fig.update_yaxes(title=\"AUC Score\")\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    title={\n",
    "    'text': \"Improved Model vs Baseline Model Predictions for 10 Different K Values\",\n",
    "    'y':0.95,\n",
    "    'x':0.5},\n",
    "    height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e25fd1-a1b3-4cf6-b4bc-2bf1b3612fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_k_6f(m, model_type, x_set, y_set): # k: 2\n",
    "    for i in range(0,10): # 2 iterations where last iteration predicts the day after tmrw \n",
    "        x_train = x_set[x_set['Date'] < end_date].set_index('Date')\n",
    "        y_train = y_set[y_set['Date'] < end_date].set_index('Date')\n",
    "        m_days = x_set[x_set['Date'] >= end_date][x_set['Date'] <= end_date + timedelta(days = m)].set_index('Date')\n",
    "        model_type.fit(x_train, y_train)\n",
    "        y_pred_array = model_type.predict(m_days)\n",
    "        y_pred = pd.DataFrame(data=y_pred_array, index = [end_date]*51*(m+1), columns=[\"party\"])\n",
    "        y_train = y_train.append(y_pred)\n",
    "    return y_train, x_set[x_set['Date'] <= end_date + timedelta(days = m)].set_index('Date')\n",
    "\n",
    "# Define a result table as a DataFrame\n",
    "result_table_6f = pd.DataFrame(columns=['model_type','m_values','fpr','tpr','auc'])\n",
    "m_values = [5,10]\n",
    "# Train the models and record the results\n",
    "for m in m_values:\n",
    "        y, x = search_k_6f(m,model_kfold, X_6b3, Y_6b3)\n",
    "        y_prob = model_kfold.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        fpr, tpr, threshold = roc_curve(y, model_kfold.predict_proba(x)[:, 1])\n",
    "        result_table_6f = result_table_6f.append({'model_type':'improved_model',\n",
    "                                            'm_values' : m,\n",
    "                                            'fpr' : fpr,\n",
    "                                            'tpr' : tpr,\n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "for m in m_values:\n",
    "        y, x = search_k_6f(m,model, X, Y)\n",
    "        y_prob = model.predict_proba(x)[:,1]\n",
    "        auc = roc_auc_score(y, y_prob)\n",
    "        fpr, tpr, threshold = roc_curve(y, model.predict_proba(x)[:, 1])\n",
    "        result_table_6f = result_table_6f.append({'model_type':'baseline_model',\n",
    "                                            'm_values' : m,\n",
    "                                            'fpr' : fpr,\n",
    "                                            'tpr' : tpr,\n",
    "                                            'auc':auc}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce9c28-6e66-41ed-99ef-7eea2bf8d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in result_table_6f.index:\n",
    "    plt.plot(result_table_6f.loc[i]['fpr'], \n",
    "             result_table_6f.loc[i]['tpr'], \n",
    "             label= result_table_6f.loc[i]['model_type'][:8] + \", \" + str(result_table_6f.loc[i]['m_values']) + \" days, \" + \"AUC={:.3f}\".format(result_table_6f.loc[i]['auc']))\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis of Improved vs Baseline Model', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
